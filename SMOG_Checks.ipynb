{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SMOG Checks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pipeton8/smog-checks/blob/main/SMOG_Checks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THXwvjv2JI98"
      },
      "source": [
        "# SMOG Checks brand and model database cleanup\n",
        "*(c) Felipe del Canto (PUC-Chile)*\n",
        "\n",
        "\n",
        "This script is designed to recognize matching brands and models of cars from a Chilean fleet database.\n",
        "\n",
        "Both models and brands are written differently in the base because of typos (i.e. NISSSAN instead of NISSAN), abbreviations (i.e. KIA instead of KIA MOTORS) or mispellings (i.e. SSANG YON instead of SSANGYON).\n",
        "\n",
        "The script implements a comparison between each pair of strings in each database, based on the Jaro distance ([link](https://rosettacode.org/wiki/Jaro_distance)). This metric was chosen since it is does not penalize typos and small misspellings as much as the Hamming distance; and is inmediatly normalized between 0 and 1.\n",
        "\n",
        "The output of this script is a txt file containing replace commands for the Stata statistical software. The goal is to make brand and model strings uniform throughout the database. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSh8ShuEdl6H"
      },
      "source": [
        "## Preamble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSQQ3Kb3rlVb"
      },
      "source": [
        "# Import files\n",
        "!wget 'https://docs.google.com/uc?export=download&id=1RnADjbJK5rM4RYsHiFAoxQrBp8atbdw-' -O 'brandsDB.txt'\n",
        "!wget 'https://docs.google.com/uc?export=download&id=1oEzvSa4fRezWCCH6EB004CUo80F9h1Vf' -O 'modelsDB.txt'\n",
        "!mkdir 'Model Cleanup'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccqe44K93O88"
      },
      "source": [
        "# Install Jaro distance library\n",
        "!pip install jellyfish"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_NQb7PYH605"
      },
      "source": [
        "# Load packages\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import jellyfish\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T05GrviII9P"
      },
      "source": [
        "# Parameters and functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "In1sCE-5NCIF"
      },
      "source": [
        "## String functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk3HZ236NEFm"
      },
      "source": [
        "# Longest word in the string\n",
        "def longestWord(s):\n",
        "  \"\"\"This function takes the longest word in a several-word string and returns it.\"\"\"\n",
        "  words = s.split()\n",
        "  maxLength = 0\n",
        "  currentLongest =  ''\n",
        "\n",
        "  for word in words:\n",
        "    if len(word) > maxLength:\n",
        "      maxLength = len(word)\n",
        "      currentLongest = word\n",
        "  \n",
        "  return currentLongest\n",
        "\n",
        "# Normalize strings\n",
        "def normalizeString(s, method):\n",
        "  \"\"\" This function \"normalizes\" a string by keeping only the alphanumeric characters\n",
        "  and spaces and then following 3 possible methods:\n",
        "  \n",
        "    if method == \"alphanumeric\":\n",
        "      The spaces are removed and the resulting string returned.\n",
        "    \n",
        "    elif method == \"longest word\":\n",
        "      The longest word is returned, using the function longestWord.\n",
        "\n",
        "    elif method == \"first n\", where n is an integer:\n",
        "      The first n characters of the string are returned\n",
        "\n",
        "  In any other case, a ValueError is raised.\n",
        "  \"\"\"\n",
        "\n",
        "  s = ''.join(e for e in s.strip() if e.isalnum() or e == \" \")\n",
        "\n",
        "  if method == \"alphanumeric\":\n",
        "    return ''.join(e for e in s if not(e == \" \"))\n",
        "\n",
        "  elif method == \"longest word\":\n",
        "    return longestWord(s)\n",
        "\n",
        "  elif method.find(\"first\") != -1:\n",
        "    size = int(method.split()[-1])\n",
        "    s = ''.join(e for e in s if not(e == \" \"))\n",
        "    return s[:size]\n",
        "\n",
        "  else:\n",
        "    raise ValueError(\"Method not implemented\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJWXc_ehO16A"
      },
      "source": [
        "## Jaro distance functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuNQ1vKGO6Jy"
      },
      "source": [
        "# Jaro distance with a lower bound\n",
        "def jaroDistancesUpToP(x, y,p=0.8):\n",
        "  \"\"\"This function compute the Jaro distance between two strings and returns it if the result is greater or equal to p. Otherwise, it returns 0.\"\"\"\n",
        "  return jellyfish.jaro_distance(x, y) * (jellyfish.jaro_distance(x, y) >= p)\n",
        "\n",
        "# Matches using the Jaro distance\n",
        "def bestMatchesUpToP(x, y,p=0.8):\n",
        "  \"\"\"This function returns True if the strings have a jaro distance of at least p and False otherwise.\"\"\"\n",
        "  return jellyfish.jaro_distance(x, y) >= p\n",
        "\n",
        "# Vectorize the functions to compute distances faster\n",
        "jaroVectorized = np.vectorize(jaroDistancesUpToP)\n",
        "matchVectorized = np.vectorize(bestMatchesUpToP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otQO6maPP_xy"
      },
      "source": [
        "## Dictionary functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdNW0437QCll"
      },
      "source": [
        "# Sort dictionary\n",
        "def sortDict(dictToSort):\n",
        "  \"\"\" This functions sorts the given dictionary according to the length of its items, in descending order.\"\"\"\n",
        "  sortedDict = sorted(dictToSort.items(), key = lambda i : len(i[1]), reverse = True)\n",
        "\n",
        "  return dict((x,y) for x,y in sortedDict)\n",
        "\n",
        "# Get matches from a dictionary\n",
        "def getMatchesDict(matches, names):\n",
        "  \"\"\" This functions receives a binary array that indicates which elements are a match (1) or not (0). \n",
        "  Then, it returns a dictionary for which every key is a brand or model indicated in 'names' and every item\n",
        "  is a list of the matches of this brand or model.\"\"\"\n",
        "  N = len(names)\n",
        "  \n",
        "  matchesDict = {}\n",
        "\n",
        "  for i in range(N):\n",
        "    matchIndex = np.argwhere(matches[i,:] == 1).flatten()\n",
        "   \n",
        "    if len(matchIndex) != 0:\n",
        "      matchesDict[names[i]] = [names[j] for j in matchIndex]\n",
        "    \n",
        "  return sortDict(matchesDict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DryduD62RgWv"
      },
      "source": [
        "## Output functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc4zZ-OaYyQw"
      },
      "source": [
        "# Write replace commands\n",
        "def writeReplaceContent(variable0,cluster,character,length,document,section=\"\",variable1=\"\",key1=\"\",close = True):\n",
        "  \"\"\" This function writes the replace comands for Stata. For the model cleanup\n",
        "  process the variable1 and key1 variables are the brand and the section is the\n",
        "  name of the model.\"\"\"\n",
        "  \n",
        "  # Obtain keys from the match dictionary. Cluster is the dictionary that contains\n",
        "  # a brand or all the models of a brand \n",
        "  keys = list(cluster.keys())\n",
        "\n",
        "  # For every key, write the replaces\n",
        "  for key in keys:\n",
        "\n",
        "    # Start with the number of the section\n",
        "    if section != \"\":\n",
        "      # For models, the sectionNumber is section-subsection\n",
        "      sectionNumber = section+\"-\"+str(keys.index(key)+1)\n",
        "    else:\n",
        "      # For brands, the sectionNumber is the number of\n",
        "      sectionNumber = str(keys.index(key)+1)\n",
        "\n",
        "    # Write the title\n",
        "    writeTitle(key,sectionNumber,character,length,document)\n",
        "    \n",
        "    # Write the commands\n",
        "    writeReplaces(variable0,key,cluster[key],document,variable1,key1)\n",
        "\n",
        "  # Close the document if asked to\n",
        "  if close:\n",
        "    document.close()\n",
        "\n",
        "  return None\n",
        "\n",
        "# Write the title\n",
        "def writeTitle(sectionTitle,sectionNumber,character,length,document):\n",
        "    \"\"\" This function writes the title for each section of commands.\n",
        "    It uses a certain 'character' to enclose the title.\"\"\"\n",
        "    \n",
        "    # Top decoration\n",
        "    document.write(\"\".join(character for i in range(length)) + \"\\n\")\n",
        "\n",
        "    # Title\n",
        "    document.write(\"{}) {}\\n\".format(sectionNumber,sectionTitle))\n",
        "\n",
        "    # Bottom decoration\n",
        "    document.write(\"\".join(character for i in range(length)) + \"\\n\")\n",
        "\n",
        "    document.write(\"\\n\")\n",
        "\n",
        "# Write each command\n",
        "def writeReplaces(variable0,key0,cluster,document,variable1=\"\",key1=\"\"):\n",
        "  \"\"\" This function writes each replace command. For the model cleanup process,\n",
        "  variable1 and key1 are the brand variable name and its value, respectively.\"\"\"\n",
        "  \n",
        "  # Cluster is a list of matches for key0\n",
        "  for key2 in cluster:\n",
        "    if variable1 != \"\":\n",
        "      # This is intended for model cleanup (key1 is the brand name)\n",
        "      document.write('replace {} = \"{}\" if {} == \"{}\" & {} == \"{}\"\\n'.format(variable0,key0,variable1,key1,variable0,key2))\n",
        "    else:\n",
        "      # This is intended for brand cleanup\n",
        "      document.write('replace {} = \"{}\" if {} == \"{}\"\\n'.format(variable0,key0,variable0,key2))\n",
        "  \n",
        "  document.write(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROa0jvtsY06B"
      },
      "source": [
        "# Main code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P79sd-U7Y5w3"
      },
      "source": [
        "## Brand cleanup function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO5qm2FWY_2W"
      },
      "source": [
        "def matchByBrand(filePath,docTitle, distance = 0.8, method = 'alphanumeric', demo = False):\n",
        "  \"\"\" This functions computes the matches by brand and writes the output document\n",
        "  for the brand cleanup process. \"\"\"\n",
        "\n",
        "  if filePath == \"\" or docTitle == \"\":\n",
        "    return None\n",
        "\n",
        "  # Read database\n",
        "  cars = pd.read_csv(filePath, keep_default_na=False)\n",
        "\n",
        "  # If demo, sample 50% of the database at random\n",
        "  if demo:\n",
        "    cars = cars.sample(frac=0.5, random_state=0)\n",
        "\n",
        "  # Normalize 'nombre_marca' and take the first and the last 5 characters\n",
        "  cars['nombreMarcaNormalized'] = cars['nombre_marca'].apply(normalizeString, args = (method,)).str.upper()\n",
        "\n",
        "  # Drop observations whose nombreMarcaNormalized is '' and reset index\n",
        "  cars = cars.loc[cars['nombreMarcaNormalized'] != '']\n",
        "  cars.reset_index(drop = True, inplace=True)\n",
        "\n",
        "  # Compute matches\n",
        "  print(\"Beginning with Normalized Brands...\", end=\"\")\n",
        "  matchesByBrand = matchVectorized(np.array(cars['nombreMarcaNormalized'])[:,np.newaxis], np.array(cars['nombreMarcaNormalized'][:]),p=distance)\n",
        "  print(\"Done!\")\n",
        "\n",
        "  # Get match dictionaries\n",
        "  clustersByBrandDict = getMatchesDict(matchesByBrand,cars['nombre_marca'])\n",
        "\n",
        "  # Create document\n",
        "  documentByBrand = open(docTitle, \"w\")\n",
        "\n",
        "  # Write them\n",
        "  print(\"Writing document...\", end=\"\")\n",
        "  writeReplaceContent('nombre_marca', clustersByBrandDict,'*',50, documentByBrand)\n",
        "  print(\"Done!\")\n",
        "\n",
        "  return None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh2e52uvZCdv"
      },
      "source": [
        "## Model cleanup function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM-NA886S10L"
      },
      "source": [
        "def matchByModel(filePath,docPath, distance = 0.8, minCount = 1000, method = \"alphanumeric\", demo = False):\n",
        "  \"\"\" This functions computes the matches by model for different brands and \n",
        "  writes the output document for the model cleanup process. \"\"\"\n",
        "\n",
        "  if filePath == \"\" or docPath == \"\":\n",
        "    return None\n",
        "\n",
        "  # Read database\n",
        "  cars = pd.read_csv(filePath, keep_default_na=False)\n",
        "\n",
        "  # If demo, sample 10% of the database at random\n",
        "  if demo:\n",
        "    cars = cars.sample(frac=0.1,random_state=0)\n",
        "\n",
        "  # Convert brands to uppercase letters\n",
        "  cars['nombre_marca']=cars['nombre_marca'].str.upper()\n",
        "  \n",
        "  # Keep brands that contain at least minCount cars\n",
        "  brandCount = cars.pivot_table(index=['nombre_marca'], aggfunc='size')\n",
        "  brandsToWork = brandCount[(brandCount >= minCount)].sort_values(ascending=False)\n",
        "\n",
        "  # Normalize 'nombre_modelo'\n",
        "  cars['nombreModeloNormalized'] = cars['nombre_modelo'].apply(normalizeString, args = (method,)).str.upper()\n",
        "\n",
        "  # Drop observations whose nombreModeloNormalized is '' and reset index\n",
        "  cars = cars.loc[cars['nombreModeloNormalized'] != '']\n",
        "  cars.reset_index(drop = True, inplace=True)\n",
        "\n",
        "  for brand in brandsToWork.keys():\n",
        "    print(\"\")\n",
        "    print(\"Starting with \" + brand)\n",
        "    \n",
        "    # Get cars of brand\n",
        "    carsOfBrand = cars.loc[cars['nombre_marca'] == brand]\n",
        "    carsOfBrand.reset_index(drop = True, inplace=True)\n",
        "\n",
        "    # Compute matches\n",
        "    print(\"- Computing Matches...\", end=\"\")\n",
        "    matchesByModel = matchVectorized(np.array(carsOfBrand['nombreModeloNormalized'])[:,np.newaxis], np.array(carsOfBrand['nombreModeloNormalized'][:]),p=distance)\n",
        "    print(\"Done!\")\n",
        "\n",
        "    # Get match dictionaries\n",
        "    print(\"- Transforming to dictionary...\", end=\"\")\n",
        "    clustersByModelDict = getMatchesDict(matchesByModel,carsOfBrand['nombre_modelo'])\n",
        "    print(\"Done!\")\n",
        "\n",
        "    # Create document\n",
        "    print(\"- Writing document...\", end=\"\")\n",
        "    sectionNumber = str(list(brandsToWork.keys()).index(brand)+1)\n",
        "    docTitle = sectionNumber + \" - \" + brand + \".txt\"\n",
        "    brandDocument = open(docPath+docTitle, \"w\")\n",
        "\n",
        "    # Write document\n",
        "    writeTitle(brand,sectionNumber,'*',50, brandDocument)\n",
        "    writeReplaceContent('nombre_modelo', clustersByModelDict,'-',30, brandDocument, section=sectionNumber, variable1='nombre_marca', key1=brand)\n",
        "    print(\"Done!\" + \"\\n\")\n",
        "\n",
        "    brandDocument.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HczAY_InZFYB"
      },
      "source": [
        "## Execution\n",
        "Expected run time in demo mode: 2 min"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBduOao5M24i"
      },
      "source": [
        "# Obtain matches and write documents\n",
        "matchByBrand(\"brandsDB.txt\",\"brandsCleanup.txt\", distance = 0.8, method = 'alphanumeric', demo = True)\n",
        "matchByModel(\"modelsDB.txt\",\"Model Cleanup/\", distance = 0.8, minCount = 1000, method = 'longest word', demo = True)\n",
        "#matchByModel(\"modelsDB.txt\",\"Model Cleanup/\", distance = 0.8, minCount = 1000, method = \"first 3\", demo = True)\n",
        "\n",
        "print(\"I'm done!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}